{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d56bda-8eae-4982-b2c8-9a570dc9ef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pnd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcaf7e9",
   "metadata": {},
   "source": [
    "Cargamos el csv para empezar el trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da27e89-3eab-48ba-ba92-be409ab5a2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tweet</td>\n",
       "      <td>existence</td>\n",
       "      <td>existence.confidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global warming report urges governments to act...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fighting poverty and global warming in Africa ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>URUGUAY: Tools Needed for Those Most Vulnerabl...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @sejorg: RT @JaymiHeimbuch: Ocean Saltiness...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global warming evidence all around us|A messag...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Migratory Birds' New Climate Change Strategy: ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Southern Africa: Competing for Limpopo Water: ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Column1    Column2  \\\n",
       "0                                              tweet  existence   \n",
       "1  Global warming report urges governments to act...        Yes   \n",
       "2  Fighting poverty and global warming in Africa ...        Yes   \n",
       "3  Carbon offsets: How a Vatican forest failed to...        Yes   \n",
       "4  Carbon offsets: How a Vatican forest failed to...        Yes   \n",
       "5  URUGUAY: Tools Needed for Those Most Vulnerabl...        Yes   \n",
       "6  RT @sejorg: RT @JaymiHeimbuch: Ocean Saltiness...        Yes   \n",
       "7  Global warming evidence all around us|A messag...        Yes   \n",
       "8  Migratory Birds' New Climate Change Strategy: ...        Yes   \n",
       "9  Southern Africa: Competing for Limpopo Water: ...        Yes   \n",
       "\n",
       "                Column3  \n",
       "0  existence.confidence  \n",
       "1                     1  \n",
       "2                     1  \n",
       "3                0.8786  \n",
       "4                     1  \n",
       "5                0.8087  \n",
       "6                     1  \n",
       "7                     1  \n",
       "8                     1  \n",
       "9                     1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensajesTwitter = pnd.read_csv(\"datas/calentamientoClimatico_sin_preparar.csv\", delimiter=\";\")\n",
    "mensajesTwitter.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b25d9",
   "metadata": {},
   "source": [
    "Vemos la dimensión del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c861efcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6091, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensajesTwitter.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f8807",
   "metadata": {},
   "source": [
    "Eliminamos la primera fila que no tiene ninguna utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5fc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensajesTwitter = mensajesTwitter.drop([0],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a475ca",
   "metadata": {},
   "source": [
    "Cambiamos el nombre de la columnas para reconocer cada una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfaddb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>CREENCIA</th>\n",
       "      <th>CONFIANZA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global warming report urges governments to act...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fighting poverty and global warming in Africa ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>URUGUAY: Tools Needed for Those Most Vulnerabl...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>@bloodless_coup \"The phrase 'global warming' s...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6087</th>\n",
       "      <td>Virginia to Investigate Global Warming Scienti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>Global warming you tube parody you will enjoy ...</td>\n",
       "      <td>No</td>\n",
       "      <td>0.6411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>One-Eyed Golfer: Don't dare tell me about glob...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>man made global warming a hair brained theory ...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6090 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET CREENCIA CONFIANZA\n",
       "1     Global warming report urges governments to act...      Yes         1\n",
       "2     Fighting poverty and global warming in Africa ...      Yes         1\n",
       "3     Carbon offsets: How a Vatican forest failed to...      Yes    0.8786\n",
       "4     Carbon offsets: How a Vatican forest failed to...      Yes         1\n",
       "5     URUGUAY: Tools Needed for Those Most Vulnerabl...      Yes    0.8087\n",
       "...                                                 ...      ...       ...\n",
       "6086  @bloodless_coup \"The phrase 'global warming' s...      Yes         1\n",
       "6087  Virginia to Investigate Global Warming Scienti...      NaN         1\n",
       "6088  Global warming you tube parody you will enjoy ...       No    0.6411\n",
       "6089  One-Eyed Golfer: Don't dare tell me about glob...       No         1\n",
       "6090  man made global warming a hair brained theory ...       No         1\n",
       "\n",
       "[6090 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names=['TWEET', 'CREENCIA', 'CONFIANZA']\n",
    "mensajesTwitter.columns = column_names\n",
    "mensajesTwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d063c93",
   "metadata": {},
   "source": [
    "Miramos a ver si tenemos algun valor nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa77edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TWEET           0\n",
       "CREENCIA     1865\n",
       "CONFIANZA       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensajesTwitter.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c9098",
   "metadata": {},
   "source": [
    "Eliminamos las filas con valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d194a497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TWEET</th>\n",
       "      <th>CREENCIA</th>\n",
       "      <th>CONFIANZA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global warming report urges governments to act...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fighting poverty and global warming in Africa ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>URUGUAY: Tools Needed for Those Most Vulnerabl...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>It's 83�_� and climbing in NYC. August weather...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6086</th>\n",
       "      <td>@bloodless_coup \"The phrase 'global warming' s...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>Global warming you tube parody you will enjoy ...</td>\n",
       "      <td>No</td>\n",
       "      <td>0.6411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6089</th>\n",
       "      <td>One-Eyed Golfer: Don't dare tell me about glob...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6090</th>\n",
       "      <td>man made global warming a hair brained theory ...</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4225 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  TWEET CREENCIA CONFIANZA\n",
       "1     Global warming report urges governments to act...      Yes         1\n",
       "2     Fighting poverty and global warming in Africa ...      Yes         1\n",
       "3     Carbon offsets: How a Vatican forest failed to...      Yes    0.8786\n",
       "4     Carbon offsets: How a Vatican forest failed to...      Yes         1\n",
       "5     URUGUAY: Tools Needed for Those Most Vulnerabl...      Yes    0.8087\n",
       "...                                                 ...      ...       ...\n",
       "6085  It's 83�_� and climbing in NYC. August weather...      Yes         1\n",
       "6086  @bloodless_coup \"The phrase 'global warming' s...      Yes         1\n",
       "6088  Global warming you tube parody you will enjoy ...       No    0.6411\n",
       "6089  One-Eyed Golfer: Don't dare tell me about glob...       No         1\n",
       "6090  man made global warming a hair brained theory ...       No         1\n",
       "\n",
       "[4225 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensajesTwitter = mensajesTwitter.dropna()\n",
    "mensajesTwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de84ad8",
   "metadata": {},
   "source": [
    "Verificamos, una vez realizada la limpieza de nulos, que ya no queda ninguno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d7c7df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TWEET        0\n",
       "CREENCIA     0\n",
       "CONFIANZA    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensajesTwitter.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca5e8d0",
   "metadata": {},
   "source": [
    "Vemos los valores únicos que tienen las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a533cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensajesTwitter['CREENCIA'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos con el proceso de lectura, para ello descargamos las librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "479c9406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/alex/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5087e6",
   "metadata": {},
   "source": [
    "Categorizamos la columna CREENCIA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d629b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 TWEET  CREENCIA CONFIANZA\n",
      "1    Global warming report urges governments to act...         1         1\n",
      "2    Fighting poverty and global warming in Africa ...         1         1\n",
      "3    Carbon offsets: How a Vatican forest failed to...         1    0.8786\n",
      "4    Carbon offsets: How a Vatican forest failed to...         1         1\n",
      "5    URUGUAY: Tools Needed for Those Most Vulnerabl...         1    0.8087\n",
      "..                                                 ...       ...       ...\n",
      "135  Report: Save the Whales and They'll Save Us fr...         1     0.823\n",
      "137  Arctic Beauty in Black and White: Alaska Befor...         1         1\n",
      "138  #EPA report documents \"very real\" impacts from...         1         1\n",
      "139  #Canadian #CEOs more keen on #green than globa...         1    0.7896\n",
      "140  RT @carbonmarket: Ask the G8 & G20 to support ...         1     0.617\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-28bb6459ddde>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mensajesTwitter['CREENCIA'] = (mensajesTwitter['CREENCIA']=='Yes').astype(int)\n"
     ]
    }
   ],
   "source": [
    "mensajesTwitter['CREENCIA'] = (mensajesTwitter['CREENCIA']=='Yes').astype(int)\n",
    "print(mensajesTwitter.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2650280a",
   "metadata": {},
   "source": [
    "Ahora, podemos crear una función llamada normalización que normalizará las frases.\n",
    "Esto significa que la función permitirá la investigación de caracteres específicos, para que luego podamos tratarlos en un proceso específico.\n",
    "\n",
    "La función re cambiará esos caracteres especiales a caracteres normales. Por ejemplo, un carácter de enlace se cambiará a una sola palabra 'URL'\n",
    "También cambiará los acentos y las mayúsculas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde6cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def normalizacion(mensaje):\n",
    "    mensaje = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL', mensaje)\n",
    "    mensaje = re.sub('@[^\\s]+','USER', mensaje)\n",
    "    mensaje = mensaje.lower().replace(\"ё\", \"е\")\n",
    "    mensaje = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', mensaje)\n",
    "    mensaje = re.sub(' +',' ', mensaje)\n",
    "    return mensaje.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc8bfb4",
   "metadata": {},
   "source": [
    "Aplicamos la función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6da1a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                TWEET  CREENCIA CONFIANZA\n",
      "1   global warming report urges governments to act...         1         1\n",
      "2   fighting poverty and global warming in africa ...         1         1\n",
      "3   carbon offsets how a vatican forest failed to ...         1    0.8786\n",
      "4   carbon offsets how a vatican forest failed to ...         1         1\n",
      "5   uruguay tools needed for those most vulnerable...         1    0.8087\n",
      "6   rt user rt user ocean saltiness shows global w...         1         1\n",
      "7   global warming evidence all around us a messag...         1         1\n",
      "8   migratory birds new climate change strategy st...         1         1\n",
      "9   southern africa competing for limpopo water cl...         1         1\n",
      "10  global warming to impact wheat rice production...         1         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-d931aa831d20>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mensajesTwitter[\"TWEET\"] = mensajesTwitter[\"TWEET\"].apply(normalizacion)\n"
     ]
    }
   ],
   "source": [
    "mensajesTwitter[\"TWEET\"] = mensajesTwitter[\"TWEET\"].apply(normalizacion)\n",
    "print(mensajesTwitter.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517bab7f",
   "metadata": {},
   "source": [
    "Ahora, comenzamos a tratar las palabras vacías que tenemos en inglés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f21ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20d206",
   "metadata": {},
   "source": [
    "Ahora que sabemos cuáles son las palabras vacías, podemos eliminarlas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5376aa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                TWEET  CREENCIA CONFIANZA\n",
      "1   global warming report urges governments act br...         1         1\n",
      "2         fighting poverty global warming africa link         1         1\n",
      "3   carbon offsets vatican forest failed reduce gl...         1    0.8786\n",
      "4   carbon offsets vatican forest failed reduce gl...         1         1\n",
      "5   uruguay tools needed vulnerable climate change...         1    0.8087\n",
      "6   rt user rt user ocean saltiness shows global w...         1         1\n",
      "7   global warming evidence around us message glob...         1         1\n",
      "8   migratory birds new climate change strategy st...         1         1\n",
      "9   southern africa competing limpopo water climat...         1         1\n",
      "10  global warming impact wheat rice production in...         1         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-57bbf70baf03>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mensajesTwitter['TWEET'] = mensajesTwitter['TWEET'].apply(lambda mensaje: ' '.join([palabra for palabra in mensaje.split() if palabra not in (stopWords)]))\n"
     ]
    }
   ],
   "source": [
    "mensajesTwitter['TWEET'] = mensajesTwitter['TWEET'].apply(lambda mensaje: ' '.join([palabra for palabra in mensaje.split() if palabra not in (stopWords)]))\n",
    "print(mensajesTwitter.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b632c",
   "metadata": {},
   "source": [
    "Aplicación de stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91c68123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                TWEET  CREENCIA CONFIANZA\n",
      "1   global warm report urg govern act brussel belg...         1         1\n",
      "2               fight poverti global warm africa link         1         1\n",
      "3   carbon offset vatican forest fail reduc global...         1    0.8786\n",
      "4   carbon offset vatican forest fail reduc global...         1         1\n",
      "5          uruguay tool need vulner climat chang link         1    0.8087\n",
      "6   rt user rt user ocean salti show global warm i...         1         1\n",
      "7   global warm evid around us messag global warm ...         1         1\n",
      "8   migratori bird new climat chang strategi stay ...         1         1\n",
      "9   southern africa compet limpopo water climat ch...         1         1\n",
      "10  global warm impact wheat rice product india lu...         1         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-6bad69e7505d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mensajesTwitter['TWEET'] = mensajesTwitter['TWEET'].apply(lambda mensaje: ' '.join([stemmer.stem(palabra) for palabra in mensaje.split(' ')]))\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "mensajesTwitter['TWEET'] = mensajesTwitter['TWEET'].apply(lambda mensaje: ' '.join([stemmer.stem(palabra) for palabra in mensaje.split(' ')]))\n",
    "print(mensajesTwitter.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3639138",
   "metadata": {},
   "source": [
    "Lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "221a9ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                TWEET  CREENCIA CONFIANZA\n",
      "1   global warm report urg govern act brussel belg...         1         1\n",
      "2               fight poverti global warm africa link         1         1\n",
      "3   carbon offset vatican forest fail reduc global...         1    0.8786\n",
      "4   carbon offset vatican forest fail reduc global...         1         1\n",
      "5          uruguay tool need vulner climat chang link         1    0.8087\n",
      "6   rt user rt user ocean salti show global warm i...         1         1\n",
      "7   global warm evid around u messag global warm d...         1         1\n",
      "8   migratori bird new climat chang strategi stay ...         1         1\n",
      "9   southern africa compet limpopo water climat ch...         1         1\n",
      "10  global warm impact wheat rice product india lu...         1         1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-0510f4d08012>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mensajesTwitter['TWEET'] = mensajesTwitter['TWEET'].apply(lambda mensaje: ' '.join([lemmatizer.lemmatize(palabra) for palabra in mensaje.split(' ')]))\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "mensajesTwitter['TWEET'] = mensajesTwitter['TWEET'].apply(lambda mensaje: ' '.join([lemmatizer.lemmatize(palabra) for palabra in mensaje.split(' ')]))\n",
    "print(mensajesTwitter.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06caca",
   "metadata": {},
   "source": [
    "Una vez que hemos hecho la preparación de las fases, estamos listos para mostrarle a nuestro algoritmo cómo tratar la información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6a2ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(mensajesTwitter['TWEET'].values,  mensajesTwitter['CREENCIA'].values,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a54deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "etapas_aprendizaje = Pipeline([('frequencia', CountVectorizer()),\n",
    "                                  ('tfidf', TfidfTransformer()),\n",
    "                                  ('algoritmo', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90023f",
   "metadata": {},
   "source": [
    "Aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "319e6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = etapas_aprendizaje.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4de0a445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8421    0.2909    0.4324       220\n",
      "           1     0.7971    0.9808    0.8795       625\n",
      "\n",
      "    accuracy                         0.8012       845\n",
      "   macro avg     0.8196    0.6359    0.6560       845\n",
      "weighted avg     0.8088    0.8012    0.7631       845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, modelo.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8562084b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why should trust scientists with global warming if they didnt know Pluto wasnt a planet'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = \"Why should trust scientists with global warming if they didnt know Pluto wasnt a planet\"\n",
    "frase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8501afb1",
   "metadata": {},
   "source": [
    "Una vez que hemos leído la frase, lo primero que vamos a hacer es normalizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76bb3142",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalización\n",
    "frase = normalizacion(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0836fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminación de las stops words\n",
    "frase = ' '.join([palabra for palabra in frase.split() if palabra not in (stopWords)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6647e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación de stemming\n",
    "frase =  ' '.join([stemmer.stem(palabra) for palabra in frase.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "051f1b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trust scientist global warm didnt know pluto wasnt planet\n"
     ]
    }
   ],
   "source": [
    "#Lematización\n",
    "frase = ' '.join([lemmatizer.lemmatize(palabra) for palabra in frase.split(' ')])\n",
    "print (frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c020cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      ">> No cree en el calentamiento climático...\n"
     ]
    }
   ],
   "source": [
    "prediccion = modelo.predict([frase])\n",
    "print(prediccion)\n",
    "if(prediccion[0]==0):\n",
    "    print(\">> No cree en el calentamiento climático...\")\n",
    "else:\n",
    "    print(\">> Cree en el calentamiento climático...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd549229",
   "metadata": {},
   "source": [
    "Ahora, quiero asegurarme de que este algoritmo funcione. Así que usaré una frase que apoye el calentamiento global para ver si la predicción final es correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76fd2f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Climate change is real, it is happening now. It is the most urgent threat facing the different species and we need to work together and not leave things for later'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = 'Climate change is real, it is happening now. It is the most urgent threat facing the different species and we need to work together and not leave things for later'\n",
    "frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f62cc9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalización\n",
    "frase = normalizacion(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b24d4dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminación de las stops words\n",
    "frase = ' '.join([palabra for palabra in frase.split() if palabra not in (stopWords)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa289325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicación de stemming\n",
    "frase =  ' '.join([stemmer.stem(palabra) for palabra in frase.split(' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dee7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "climat chang real happen urgent threat face differ speci need work togeth leav thing later\n"
     ]
    }
   ],
   "source": [
    "#Lematización\n",
    "frase = ' '.join([lemmatizer.lemmatize(palabra) for palabra in frase.split(' ')])\n",
    "print (frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62c94d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      ">> Cree en el calentamiento climático...\n"
     ]
    }
   ],
   "source": [
    "prediccion = modelo.predict([frase])\n",
    "print(prediccion)\n",
    "if(prediccion[0]==0):\n",
    "    print(\">> No cree en el calentamiento climático...\")\n",
    "else:\n",
    "    print(\">> Cree en el calentamiento climático...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272a2b82",
   "metadata": {},
   "source": [
    "Uso de SVM para el mismo proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f1fc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definición de la canalización\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "etapas_aprendizaje = Pipeline([('frequencia', CountVectorizer()),\n",
    "                                  ('tfidf', TfidfTransformer()),\n",
    "                                  ('algoritmo', svm.SVC(kernel='linear', C=2))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce97c7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7143    0.5909    0.6468       220\n",
      "           1     0.8643    0.9168    0.8898       625\n",
      "\n",
      "    accuracy                         0.8320       845\n",
      "   macro avg     0.7893    0.7539    0.7683       845\n",
      "weighted avg     0.8252    0.8320    0.8265       845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aprendizaje\n",
    "modelo = etapas_aprendizaje.fit(X_train,y_train)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, modelo.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "632edbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Búsqueda del mejor parámetro C\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parametrosC = {'algoritmo__C':(1,2,4,5,6,7,8,9,10,11,12)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fdc0b552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algoritmo__C': 2}\n"
     ]
    }
   ],
   "source": [
    "busquedaCOptimo = GridSearchCV(etapas_aprendizaje, parametrosC,cv=2)\n",
    "busquedaCOptimo.fit(X_train,y_train)\n",
    "print(busquedaCOptimo.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba14d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parámetro nuevo C=1\n",
    "etapas_aprendizaje = Pipeline([('frequencia', CountVectorizer()),\n",
    "                                  ('tfidf', TfidfTransformer()),\n",
    "                                  ('algoritmo', svm.SVC(kernel='linear', C=1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bfa1542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7368    0.5727    0.6445       220\n",
      "           1     0.8605    0.9280    0.8930       625\n",
      "\n",
      "    accuracy                         0.8355       845\n",
      "   macro avg     0.7987    0.7504    0.7687       845\n",
      "weighted avg     0.8283    0.8355    0.8283       845\n",
      "\n"
     ]
    }
   ],
   "source": [
    "modelo = etapas_aprendizaje.fit(X_train,y_train)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, modelo.predict(X_test), digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "472f3460692ba2c0861145e5e150d03c8a5c0e40e057944a047c431b9050b93d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
